{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and import general libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in file\n",
    "data = pd.read_csv('diamonds.csv')\n",
    "\n",
    "# drop the index column\n",
    "data = data.drop(data.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform cut to int\n",
    "def trans_cut(x):\n",
    "    if x == \"Fair\": return 4\n",
    "    if x == \"Good\": return 3\n",
    "    if x == \"Very Good\": return 2\n",
    "    if x == \"Ideal\": return 1\n",
    "    if x == \"Premium\": return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform color into int\n",
    "def trans_color(x):\n",
    "    if x == \"D\": return 0\n",
    "    if x == \"E\": return 1\n",
    "    if x == \"F\": return 2\n",
    "    if x == \"G\": return 3\n",
    "    if x == \"H\": return 4\n",
    "    if x == \"I\": return 5\n",
    "    if x == \"J\": return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform clarity to int\n",
    "def trans_clarity(x):\n",
    "    if x == \"I1\": return 7\n",
    "    if x == \"SI1\": return 6\n",
    "    if x == \"SI2\": return 5\n",
    "    if x == \"VS1\": return 4\n",
    "    if x == \"VS2\": return 3\n",
    "    if x == \"VVS1\": return 2\n",
    "    if x == \"VVS2\": return 1\n",
    "    if x == \"IF\": return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace current columns with new int versions\n",
    "data['cut'] = data['cut'].apply(trans_cut)\n",
    "data['color'] = data['color'].apply(trans_color)\n",
    "data['clarity'] = data['clarity'].apply(trans_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "data = data[(data[['x', 'y', 'z']] != 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cut = LabelEncoder()\n",
    "label_color = LabelEncoder()\n",
    "label_clarity = LabelEncoder()\n",
    "data['cut'] = label_cut.fit_transform(data['cut'])\n",
    "data['color'] = label_color.fit_transform(data['color'])\n",
    "data['clarity'] = label_clarity.fit_transform(data['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting to train and test\n",
    "X = data.drop(['price'], axis=1)\n",
    "y = data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSquared_Scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model_type):\n",
    "    start_time = time.time()\n",
    "    model = model_type\n",
    "    model.fit(X_train , y_train)\n",
    "    cross_val_results = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5,verbose = 1)\n",
    "\n",
    "    y_predict = model.predict(X_test)\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print(model_type)\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print('Results: %.2f' % model.score(X_test, y_test))\n",
    "    print(cross_val_results)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    rmse = mean_squared_error(y_test, y_predict)**0.5\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    mae = mean_absolute_error(y_test, y_predict)\n",
    "\n",
    "    print()\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print('\\n\\n')\n",
    "\n",
    "    RSquared_Scores.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScaledSGDRegression():\n",
    "    start_time = time.time()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    Xs = scaler.transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3, random_state=309)\n",
    "    sgd = linear_model.SGDRegressor()\n",
    "    sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred=sgd.predict(X_test)\n",
    "    print('Results: %.2f' % sgd.score(X_test, y_test))\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print()\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScaledSVR():\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    print('###### Support Vector Regression (SVR) #######')\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    Xs = scaler.transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3, random_state=309)\n",
    "\n",
    "\n",
    "    #Then we fit the regressor to the scaled dataset :\n",
    "\n",
    "    #fitting the SVR to the dataset\n",
    "\n",
    "    regressor = SVR(kernel='rbf',C=100)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred=regressor.predict(X_test)\n",
    "\n",
    "    print('')\n",
    "    print('Score : %.4f' % regressor.score(X_test, y_test))\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    eval_model(LinearRegression())\n",
    "    eval_model(KNeighborsRegressor())\n",
    "    eval_model(Ridge(alpha=1.0))\n",
    "    eval_model(tree.DecisionTreeClassifier())\n",
    "    ScaledSGDRegression()\n",
    "    ScaledSVR()\n",
    "    eval_model(RandomForestRegressor())\n",
    "    eval_model(GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=309, loss='ls', verbose=1))\n",
    "    eval_model(LinearSVR(random_state=309, tol=1e-5))\n",
    "    eval_model(MLPRegressor(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.90\n",
      "[0.89960819 0.88622343 0.89116416 0.88766085 0.88709594]\n",
      "\n",
      "MSE    : 1631602.42 \n",
      "RMSE   : 1277.34 \n",
      "R2     : 0.90 \n",
      "MAE    : 839.32 \n",
      "--- 0.21569132804870605 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.95\n",
      "[0.94658    0.9402005  0.94412738 0.94430429 0.94733194]\n",
      "\n",
      "MSE    : 834834.37 \n",
      "RMSE   : 913.69 \n",
      "R2     : 0.95 \n",
      "MAE    : 493.63 \n",
      "--- 11.252387762069702 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.90\n",
      "[0.89957876 0.88678949 0.89118191 0.88769838 0.88710878]\n",
      "\n",
      "MSE    : 1632206.75 \n",
      "RMSE   : 1277.58 \n",
      "R2     : 0.90 \n",
      "MAE    : 839.73 \n",
      "--- 0.13843178749084473 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.15\n",
      "[0.0927881  0.1314208  0.17173276 0.2021298  0.23699278]\n",
      "\n",
      "MSE    : 1265370.00 \n",
      "RMSE   : 1124.89 \n",
      "R2     : 0.92 \n",
      "MAE    : 512.00 \n",
      "--- 344.23788952827454 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "Results: 0.90\n",
      "\n",
      "MSE    : 1660487.66 \n",
      "RMSE   : 1288.60 \n",
      "R2     : 0.90 \n",
      "MAE    : 839.26 \n",
      "--- 0.6043992042541504 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "###### Support Vector Regression (SVR) #######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score : 0.9416\n",
      "\n",
      "MSE    : 949286.03 \n",
      "MAE    : 507.52 \n",
      "RMSE   : 974.31 \n",
      "R2     : 0.94 \n",
      "--- 402.3848602771759 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.98\n",
      "[0.97731269 0.97759004 0.97734132 0.9788847  0.98072345]\n",
      "\n",
      "MSE    : 320793.45 \n",
      "RMSE   : 566.39 \n",
      "R2     : 0.98 \n",
      "MAE    : 285.01 \n",
      "--- 22.53803324699402 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1    13922923.5412            2.16s\n",
      "         2    12356513.3895            2.00s\n",
      "         3    11048953.3341            1.86s\n",
      "         4     9876324.7146            1.79s\n",
      "         5     8918328.9926            1.74s\n",
      "         6     8049373.8783            1.69s\n",
      "         7     7336758.5994            1.67s\n",
      "         8     6693968.1202            1.63s\n",
      "         9     6154764.3722            1.61s\n",
      "        10     5690091.1067            1.58s\n",
      "        20     3171705.7594            1.38s\n",
      "        30     2359314.4902            1.18s\n",
      "        40     2053467.0788            1.02s\n",
      "        50     1865713.4483            0.85s\n",
      "        60     1724094.1079            0.68s\n",
      "        70     1615324.2040            0.51s\n",
      "        80     1529606.2544            0.34s\n",
      "        90     1461137.5442            0.17s\n",
      "       100     1406392.8120            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1    13981875.5136            1.36s\n",
      "         2    12408434.3774            1.31s\n",
      "         3    11091065.8039            1.30s\n",
      "         4     9913714.1663            1.27s\n",
      "         5     8946257.7908            1.26s\n",
      "         6     8073370.8385            1.24s\n",
      "         7     7356070.2947            1.23s\n",
      "         8     6710784.0067            1.22s\n",
      "         9     6175674.2591            1.21s\n",
      "        10     5706681.2601            1.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        20     3190214.3387            1.08s\n",
      "        30     2377212.5155            0.92s\n",
      "        40     2069318.5048            0.79s\n",
      "        50     1878273.9236            0.66s\n",
      "        60     1735273.8718            0.53s\n",
      "        70     1625518.8199            0.39s\n",
      "        80     1539358.4216            0.26s\n",
      "        90     1470645.5837            0.13s\n",
      "       100     1415879.0550            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1    13893107.8170            1.36s\n",
      "         2    12329580.8855            1.32s\n",
      "         3    11017728.7179            1.30s\n",
      "         4     9859176.4775            1.28s\n",
      "         5     8894380.3854            1.27s\n",
      "         6     8036596.6695            1.25s\n",
      "         7     7318914.9464            1.24s\n",
      "         8     6683996.0512            1.23s\n",
      "         9     6141709.6061            1.22s\n",
      "        10     5669210.8748            1.22s\n",
      "        20     3165780.8452            1.06s\n",
      "        30     2352553.6549            0.93s\n",
      "        40     2045985.8609            0.79s\n",
      "        50     1858738.8932            0.66s\n",
      "        60     1717118.3131            0.52s\n",
      "        70     1609084.2497            0.39s\n",
      "        80     1523465.3103            0.26s\n",
      "        90     1455328.2857            0.13s\n",
      "       100     1400558.3619            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1    13866692.8118            1.61s\n",
      "         2    12309128.6999            1.55s\n",
      "         3    11009436.6485            1.45s\n",
      "         4     9843559.4490            1.40s\n",
      "         5     8890432.9206            1.36s\n",
      "         6     8024999.8445            1.33s\n",
      "         7     7315030.0261            1.31s\n",
      "         8     6684768.4526            1.28s\n",
      "         9     6142515.0300            1.26s\n",
      "        10     5673383.2844            1.24s\n",
      "        20     3163763.2913            1.08s\n",
      "        30     2352826.0765            0.94s\n",
      "        40     2047122.9324            0.81s\n",
      "        50     1857625.7683            0.67s\n",
      "        60     1714756.4468            0.53s\n",
      "        70     1604012.2500            0.40s\n",
      "        80     1518080.2520            0.26s\n",
      "        90     1449262.5250            0.13s\n",
      "       100     1394164.1400            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1    13922933.0766            1.36s\n",
      "         2    12352992.4303            1.32s\n",
      "         3    11042845.5079            1.29s\n",
      "         4     9879175.0878            1.27s\n",
      "         5     8912392.4313            1.26s\n",
      "         6     8048985.9473            1.24s\n",
      "         7     7330596.0274            1.23s\n",
      "         8     6693032.5538            1.22s\n",
      "         9     6152816.6045            1.21s\n",
      "        10     5680532.1081            1.21s\n",
      "        20     3167252.4565            1.06s\n",
      "        30     2360170.3606            0.92s\n",
      "        40     2056138.6804            0.78s\n",
      "        50     1869708.7474            0.65s\n",
      "        60     1729145.1691            0.52s\n",
      "        70     1620062.8088            0.39s\n",
      "        80     1534767.9291            0.26s\n",
      "        90     1466296.3016            0.13s\n",
      "       100     1411991.2917            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1    13949858.2106            1.57s\n",
      "         2    12378129.7679            1.46s\n",
      "         3    11055275.2714            1.47s\n",
      "         4     9905512.7692            1.41s\n",
      "         5     8932625.0241            1.37s\n",
      "         6     8075182.1990            1.33s\n",
      "         7     7344670.0875            1.30s\n",
      "         8     6704944.8929            1.28s\n",
      "         9     6163976.2547            1.26s\n",
      "        10     5687417.4082            1.24s\n",
      "        20     3159013.4249            1.08s\n",
      "        30     2339179.4688            0.92s\n",
      "        40     2034623.7138            0.80s\n",
      "        50     1850914.5054            0.66s\n",
      "        60     1710709.0921            0.53s\n",
      "        70     1603597.5574            0.40s\n",
      "        80     1519404.6140            0.26s\n",
      "        90     1451818.4822            0.13s\n",
      "       100     1397863.5225            0.00s\n",
      "----------------------------------------------------------------------------\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=1,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=309, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.91\n",
      "[0.91222284 0.90938206 0.90814609 0.91043136 0.90559089]\n",
      "\n",
      "MSE    : 1427945.21 \n",
      "RMSE   : 1194.97 \n",
      "R2     : 0.91 \n",
      "MAE    : 699.97 \n",
      "--- 8.753675699234009 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.9s finished\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "          random_state=309, tol=1e-05, verbose=0)\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.80\n",
      "[0.78640556 0.79159533 0.79217063 0.79451085 0.78743554]\n",
      "\n",
      "MSE    : 3274041.47 \n",
      "RMSE   : 1809.43 \n",
      "R2     : 0.80 \n",
      "MAE    : 1059.18 \n",
      "--- 5.058933258056641 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "----------------------------------------------------------------------------\n",
      "Results: 0.95\n",
      "[0.94660291 0.92787993 0.94341438 0.9478669  0.94640326]\n",
      "\n",
      "MSE    : 858964.08 \n",
      "RMSE   : 926.80 \n",
      "R2     : 0.95 \n",
      "MAE    : 541.45 \n",
      "--- 1695.658480167389 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karu/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 22.6min finished\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
